\documentclass[11pt,a4paper]{article}

\usepackage{caption}
\usepackage{amsfonts, amsmath, amsthm, amssymb}
\usepackage{fancyhdr, lipsum}
\usepackage{graphicx}
\usepackage{mathptmx}
\usepackage[usenames, dvipsnames]{xcolor}
\usepackage[a4paper, pdftex]{geometry}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage{multirow}
\usepackage[lined,boxed,ruled,commentsnumbered]{algorithm2e}
\usepackage{xcolor}
\usepackage{pifont}
\usepackage{fontspec, xltxtra, xunicode}
\usepackage[slantfont, boldfont]{xeCJK}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subfig}
\geometry{left=2.5cm, right=2.5cm, top=2cm, bottom=2.5cm}
\hypersetup{colorlinks=true, linkcolor=blue}
\fboxrule=0.5pt
\fboxsep=4pt

\pagestyle{fancy}
\setcounter{tocdepth}{5}
\setcounter{secnumdepth}{5}
\setmainfont{Norasi}
%\hypersetup{pagebackref, colorlinks}
\hypersetup{colorlinks=true, linkcolor=blue}
\fboxrule=0.5pt
\fboxsep=4pt
\setlength{\tabcolsep}{8pt}
\renewcommand{\arraystretch}{1.5}


\begin{document}

\title{\color{blue}\textbf{Transition Probability-based Resource Selection Algorithm}}
\author{\small Author(author@vmware.com)\\
%\small Junping Du(jdu@vmware.com)\\
%\small Emma Lin(line@vmware.com)\\
%\small Binglin Chang(bchang@vmware.com)\\
%\small Terry Li(tli@vmware.com)\\
%\small Jun Wang(wjun@vmware.com)\\
%\small Xinhui Li(lxinhui@vmware.com)\\
}
\date{\today}
\maketitle

\section{\textbf\normalsize{Abstract}}

Hadoop implements a Round-Robin algorithm for
its local disks allocation to balance their I/O loading.
But when a cluster deployed on virtualization environment, a physical host may place multiple
virtual nodes, and a physical disk is mapped by multiple virtual 
disks. In this case, disk contention on physical layer is hard to control because each 
virtual disk is scheduled separately.
This paper provides a solution to enhance virtual disks allocation policy of Hadoop under
virtualzation environment. And focus on the resource selection 
algorithm about scheduling multiple resource candidates with different capcacity.
The simulation result demonstrate the effectiveness of our algorithm, and the compute complexity
analysis shows it is able to be applied to production environment.

\section{\textbf\normalsize{Description}}

Hadoop has become very widespread across industries, 
especially in web companies. For each node's disks,
Hadoop implements a Round-Robin scheme for disk allocation,
this algorithm allocates the candidate disks one by 
one for every incoming disk I/O request. The purpose of this design is to balance 
the I/O loading of local disks, and is used by both MapReduce framework and HDFS 
management. But if Hadoop cluster is deployed on virtualization environment, every node is 
a virtual machine(VM), the disk I/O occurs on VM's disks is actually 
mapped to physical host's disks rather than interact with hardware directly.

\begin{table}
\centering
\caption{Virtual Disks to Physical Disks mapping topology}
\begin{tabular}{|c|c|c|}
\hline
\multirow{3}{*}{\textbf{pHost1}} &  \textbf{$VM_1$} & \textbf{$VM_2$} \\
\cline{2-3}
                        & $vDisk_{11} \mapsto pHost1:pDisk1$ & $vDisk_{21} \mapsto pHost1:pDisk2$ \\
                        & $vDisk_{12} \mapsto pHost1:pDisk2$ & $vDisk_{22} \mapsto pHost1:pDisk3$ \\
\hline
\multirow{4}{*}{\textbf{pHost2}} & \textbf{$VM_3$} & \textbf{$VM_4$} \\
\cline{2-3}
                        & $vDisk_{31} \mapsto pHost2:pDisk1$ & $vDisk_{41} \mapsto pHost2:pDisk1$ \\
                        & $vDisk_{32} \mapsto pHost2:pDisk2$ & \\
                        & $vDisk_{33} \mapsto pHost2:pDisk3$ & \\
\hline
\end{tabular}
\label{table:origindata}
\end{table}

Consider table ~\ref {table:origindata}, for physical host pHost1,
\textbf{$VM_1$} and \textbf{$VM_2$} are hosted on a same physical 
host, \textbf{$VM_1$}'s disks are created from physical host's physical disk 1 and 
physical disk 2, \textbf{$VM_2$}'s are from physical disk 2 and physical disk 3. 
The I/O throughput on each virtual disk of a VM is ultimately redirected 
to the corresponding physical disk. If the I/O load across virtual disks of 
each VM is in balance, and all VMs are fairly scheduled. 
Then the physical I/O load on physical disk 2 will be heavier than that on 
physical disk 1 and physical disk 3.

To overcome this limitation, we propose a solution which can be summized as 3 steps:

\begin{itemize}
\item For each physical host, collect its disk topology which maps each VM's virtual disks
  to this host's physical disks.
\item Calculate the disk allocation probability distribution for each VM, section ~\ref{sec:problem1}
  provides a common algorithm for this problem, since this algorithm is straight forward and can 
  find the exact root, we do not provide simulation result.
\item Determine disk allocation order based on probability distribution, this step is 
  described in section ~\ref{sec:problem2} and simulated in section ~\ref{sec:exp},
  and it is the core value of this paper.
\end{itemize}

\section{\textbf {Calculate Disk Allocation Probability Distribution}}
\label{sec:problem1}

Take table ~\ref{table:topology} as example, in this case, $[VM_1,VM_2,...,VM_n]$ are hosted 
on a physical host which contains $m$ physical disks($pDisk_1,pDisk_2,...,pDisk_m$), 
$a_{ij}$ is the $VM_{i}$'s allocation probability for its virtual disk which maps to $pDisk_j$.

\begin{table}
\centering
\caption{Disk Mapping Topology of a Given Physical Host}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
& $pDisk_1$ & $pDisk_2$ & $pDisk_3$ & ... & $pDisk_m$ \\
\hline
$VM_1$ & $a_{11}$ & $a_{12}$ & & & \\
\hline
$VM_2$ & & $a_{22}$ & $a_{23}$ & & $a_{2m}$ \\
\hline
$VM_3$ & $a_{31}$ & $a_{32}$ & & & \\
\hline
... & & & & & \\
\hline
$VM_n$ & $a_{n1}$ & & $a_{n3}$ & & $a_{nm}$ \\
\hline
\end{tabular}
\label{table:topology}
\end{table}

Our target is to balance I/O loading among physical disks, this can be descriped as 
an simple optimization issue with linear constraints:
\begin{equation}
\begin{split}
  min\ &\sum_{j=1}^{m} (\sum_{i=1}^{n} a_{ij} - \frac{n}{m})^2 \\
  subject\ to\ &\sum_{j=1}^{m} a_{ij} = 1,\ \forall i  \\
           &a_{ij} = 0,\ \forall (i,j) \notin \Omega \\
           &0 \leq a_{ij} \leq 1,\ \forall (i,j) \in \Omega
\end{split}
\label{equ:convex}
\end{equation}

Here, $\Omega$ is defined as the union of VMs and physical disks pairs.
Let $M_{i}$ be the number of physical disks $VM_{i}$ occupies. Then a iterative 
algorithm to calculate the the root of this equation ~\ref{equ:convex}
is descriped by algorithm ~\ref{alg:iteration1}.

\begin{algorithm}[H]
%\SetAlgoLined
\KwData{disk mapping topology of a given VM}
\KwResult{the allocation probability distribution of each virtual disk}
initialization: let $K=1000, \epsilon=10^{-4}$\;
\lForEach{$i \in (1,n)$}{\
  $a_{ij_1}=a_{ij_2}=...=a_{ij_{M_i}}=\frac{1}{M_i}$ \;
}
\For{$t\leftarrow 0$ \KwTo $K$}{
  $done = 1$\;
  \lForEach{$j \in [1,m]$}{\
    $S_j=\sum_{i=1}^{n} a_{ij}$\;
  }
  \lForEach{$j \in [1,m]$}{\
    \eIf{$|S_j - \frac{n}{m}| > \epsilon$}{
      $done = 0$\;
      break\;
    }{
      continue\;
    }
  }
  \eIf{$done == 1$}{
    return matrix $\mathbf a$;
  }{
    \emph{adjust probability values to approximate optimal values}\;
    \lForEach{$a_{ij}, i \in (1,n), j \in (1,m)$}{\
      $a_{ij} = a_{ij} * \frac{n}{mS_j}$\;
    }
    \lForEach{$i \in (1,n)$}{\
      $T_i=\sum_{j=1}^{m} a_{ij}$\;
    }
    \lForEach{$a_{ij}, i \in (1,n), j \in (1,m)$}{\
      $a_{ij} = \frac{a_{ij}}{T_i}$\;
    }
  }
}
\caption{calculate disk allocation probability distribution}
\label{alg:iteration1}
\end{algorithm}

\section{\textbf {Transition Probability-based Resource Selection}}
\label{sec:problem2}

Given a VM and its steady-state allocation probability for virtual disks
$\mathbf{A} = [a_1,a_2,...,a_n]$, where $n$ is $\mathbf A$'s virutual disks 
number. We need an algorithm to select a virtual disk for each
incoming I/O request in this section.

\subsection{Design Target}
Our target is to balance the I/O loading 
at real-time, this means any length of sequence generated by this algorithm should
approximate to $\mathbf{A}$.

For example, assume steady-state disks allocation 
probability is $[0.1,0.2,0.3,0.4]$,  then no matter request for 5, 10, 20 or 200 times, the
generated sequence determined by our algorithm should approximate to $[0.1, 0.2, 0.3, 0.4]$.

\subsection{Algorithms Description}
To acheive this target, our solution is based on transition probability matrix,
assume the probability distribution for last request is 
\begin{equation}
\mathbf{A}^{k} = [a_1^k,a_2^k,...,a_n^k]
\end{equation}
and there is a transition matrix $\mathbf{P}_A$ given, then the probability distribution of current request is
\begin{equation}
\mathbf{A}^{k+1} = \mathbf{A}^{k} \mathbf{P}_A
\end{equation}

We need to customize $\mathbf{P}_A$ to get better performance, firstly, define steplength $d_{k, k+1}$ as:
\begin{equation}
d_{k,k+1} = |(index_{k+1} - index_{k})\ mod \ n|
\label{equ:steplength}
\end{equation}

In this equation, $index_{k}$ defined as the selected disk's index number corresponding to $\mathbf{A}$ for 
the $k$th request. Generally, our idea is to minimize the these steplengths $[d_{0,1},d_{1,2},...,d_{k,k+1},...]$.
By doing this, the selection algorithm will tend to select virtual disk one by one to guarantee 
the disk balance even for very limited times of request. 

If we consider Round-Robin algorithm from the perspective of transition probabilty, its steplength is always 1 actually.

Then, for transition probability matrix
\begin{equation}
  \mathbf{P}_A = 
  \begin{pmatrix}
    0 & p_{1,2} & p_{1,3} & \cdots & p_{1,n} \\
    p_{2,1} & 0 & p_{2,3} & \cdots & p_{2,n} \\
    p_{3,1} & p_{3,2} & 0 & \cdots & p_{3,n} \\
     \cdots & \cdots & \cdots & \cdots \\
    p_{n,1} & p_{n,2} & p_{n,3} & \cdots & 0
  \end{pmatrix}
\end{equation}

If virtual disk $i$ is selected last time, this time virtual disk $j$ will 
be selected by probability $p_{ij}$. Minimizing steplengths equals to equation ~\ref{equ:sort}, $\beta_j$ actually reperents
the number of non-zero elements of $j$th column of $\mathbf{P}_A$.
\begin{equation}
  \begin{split}
  min\ & \beta_j, \forall j \\
  s.t\ & a_{j} = a_{j-1}*p_{j-1,j} + a_{j-2}*p_{j-2,j} + ... + a_{j-\beta}*p_{j,\beta_j}
\end{split}
\label{equ:sort}
\end{equation}

The first thing is realigning $\mathbf{A}$ to make sure the adjacent elements do not different too much.
Asending sort $\mathbf {A}$ as $\mathbf{\bar{A}} = [\bar{a_1},\bar{a_2},...,\bar{a_n}]$. 
if $n$ is odd, let $\mathbf{B} = [\bar{a_1},\bar{a_3},\bar{a_5},...,\bar{a_{N-1}},\bar{a_{N}},\bar{a_{N-2}},\bar{a_{N-4}},...,\bar{a_4},\bar{a_2}]$, 
else, $\mathbf{B} = [\bar{a_1},\bar{a_3},\bar{a_5},...,\bar{a_{N-2}},\bar{a_{N}},\bar{a_{N-1}},\bar{a_{N-3}},...,\bar{a_4},\bar{a_2}]$

Then let $\mathbf{P}_B$ be the transition probability matrix for $\mathbf{B}$,
initialize $\beta_j$ for each $b_j$ by algorithm ~\ref{alg:num}:

\begin{algorithm}[H]
%\SetAlgoLined
  \KwData{realigned steady-state probability distribution $\mathbf{B}$}
  \KwResult{no-zero elements number $\beta_j$ for each column of $\mathbf{P}_B$}
\lForEach{$j \leftarrow 1$ \KwTo $n$}{\
  sum = 0\;
  \For{$t\leftarrow 1$ \KwTo $n$}{
    $sum += b_{i-t}$\;
    \If{$sum \geq b_{j}$}{
      $\beta_j\ =\ t$\;
      break\;
    }
  }
}
\caption{Determine no-zero elements number for each column of $\mathbf{P}_B$}
\label{alg:num}
\end{algorithm}

Then, our problem can be concluded as optimizing $\widetilde{\mathbf{P}_B}$ under
linear constraint, as described by equation ~\ref{equ:optimize}, an interative algorithm is
provided by ~\ref{alg:opt}
\begin{equation}
\begin{split}
  min & ||\mathbf{B}\hat{P}_B-\mathbf{B}||_{2} \\
 s.t. & \sum_{j=1}^{m} p_{ij}=1, \forall i \\
      & p_{ij} = 0, \forall (i,j) \notin \Omega_{\hat{P}_B} \\
      & 0 \leq p_{ij} \leq 1, \forall (i,j) \in \Omega_{\hat{P}_B}
\end{split}
\label{equ:optimize}
\end{equation}

\begin{algorithm}[H]
  \KwData{$\mathbf{B}$ and $\beta_j,\forall j$}
  \KwResult{Transition probability matrix $\mathbf{P}_B$}
  initialization: let $K=1000, \epsilon=10^{-5}$\;
  \For{$t \leftarrow 1$ \KwTo $K$}{\
    \For{$i \leftarrow 1$ \KwTo $n$}{\
      count number of no-zero elements number $M$ based on all $\beta_j$\;
      \lForEach{$j$}{
        $p_{ij} = \frac{1}{M}$\;
      }
    }
    calculate $\hat{\mathbf{B}} = \mathbf{BP_B}$\;
    \If{$\sum_i {(\hat{b_i}-b_i)^2} < \epsilon$}{
      return $\mathbf{B}$\;
    }
    \lForEach{$i$}{
      $c_i=\frac{\hat{b_i}}{b_i}$\;
    }
    \lForEach{$i,j$}{
      $p_{ij} = \frac{p_{ij}}{c_i}$
    }
  }
  \caption{Calculate $\widetilde{\mathbf{P}_B}$ of given $\beta_j, \forall j$}
  \label{alg:opt}
\end{algorithm}

In some cases, with the input $\beta_j, \forall j$,  algorithm ~\ref{alg:num} is
not be able to convergent to the given $\epsilon$(set to $10^{-5}$), to solve it,
a greedy stragety is designed as algorithm ~\ref{alg:greedy}. Since 
$\mathbf{P}_B \to \mathbf{I}$ can satify 
$||\mathbf{B}\hat{P}_B-\mathbf{B}||_{2} < \epsilon, \forall \epsilon$,
algorithm ~\ref{alg:greedy} will not run forever.

\begin{algorithm}[H]
\While{True}{\
  run algorithm ~\ref{alg:opt};
  \If{cannot achieve $\sum_i {(\hat{b_i}-b_i)^2} < \epsilon$}{\
    save $\widetilde{\mathbf{P_B}}$\ calculated by ~\ref{alg:opt}\;
    find $k_{min} = \{k|\beta_j,k^{'} > \beta_j,k_{min}, \forall k^{'}\}$\;
    \eIf{$\beta_j[k_{min}] == len(\mathbf{B})$}{
      break
    }{
      $\beta_j[k_{min}] += 1$\;
      re-initialize a new $\mathbf{P_B}$ based on new $\beta_j$\;
      $\mathbf{P_B} = 0.5 * (\mathbf{P_B} + \widetilde{\mathbf{P_B}})$
    }
  }
}
\caption{Greedy algorithm to convergent to $\epsilon$ always}
\label{alg:greedy}
\end{algorithm}

Finally, let $e_i=(0,0,...,1,0,...,0)^{T}$, where the i element equals 1, all 
others equal 0, then the resource allocation policy for each request can 
be described as algorithm ~\ref{alg:final}.

\begin{algorithm}[H]
  \KwData{steady-state probability distrubution $\mathbf{B}$, constant $\eta \in [0,1]$}
  \KwResult{sequence [$\gamma_k$]}
  initialization: $\alpha=random(n)$, $\pi_{0} = e_{\alpha}$\;
  calculate transition probability matrix $\mathbf{P}$ of $\mathbf{B}$\;
  \For{$k$th request from client, $k >= 1$}{
    init selected resource $\gamma_{k}=0$ and $S=0$\;
    calculate $\pi_{k} = \pi_{k-1} \mathbf{P}$ by following algorithm ~\ref{alg:greedy}\;
    %select disk $\gamma_{k}$ based on the prabability $\pi_{k}$(TODO: describe details)\;
    random a float value $\phi \in [0,1]$\;
    \For{$t\leftarrow 1$ \KwTo $n$}{
      $S += \pi_k[t]$\;
      \If{$sum \geq \phi$}{
        $\gamma_{k} = t$ and output $\gamma_{k}$\;
        break\;
      }
    }
    adjust $\pi_{k} = (1-\eta)\pi_{k} + \eta*e_{\gamma_{k}}$\;
  }
\caption{Algorithm 1}
\label{alg:final}
\end{algorithm}

Based on this algorithm, we can guarantee the generated resource sequence 
approximate to the steady-state probability distribution, no matter how long
the sequence is. In another word, select given resources in balance at real-time.
If all the probability values of the steady-state distribution are the same, this algorithm 
is equivalent to Round-Robin algorithm.

\subsection{\textbf{Compute Complexity Anylisis}}

Consider algorithm ~\ref{alg:greedy} and ~\ref{alg:opt}, the compute complexity of this
algorithm is $o(RKn^2)$, where $R$ is the loop times of algorithm ~\ref{alg:greedy}, $K$ is
the loop times mentioned in algorithm ~\ref{alg:opt}, and $n$ is the number of resource candidates.

The maximum value $R$ is $n^{2}$ in worst cases, and is determined by $\epsilon$ set by
algorithm ~\ref{alg:opt}, our experiments in section ~\ref{sec:exp} shows
set $\epsilon$ to $10^{-4}$ or $10^{-5}$ is enough and $R$ would be
much less than $n^{2}$.

For parameter $K$, in algorithm ~\ref{alg:opt} we set it to 1000 for insurance. 
In our experiments, the declining speed of $\sum_i {(\hat{b_i}-b_i)^2}$ would be very very slow after
adjusted for dozens of times, which means most loops of this step can be skipped 
if the implementation is awaring of declining speed.

Furthermore, this calculation of transition probability matrix is only need to be executed at the initialization of 
the resource allocator or when resource candidates changed.
So generally, the algorithm itself will not involve much compute resource and can be applied
to production environment.

\section{\textbf\normalsize{Experiment}}
\label{sec:exp}
\subsection{\textbf evaluation standard}
\subsection{\textbf {similarity Definition}}
Based on cos similarity function to compare two vectors
\begin{equation}
S(\mathbf{B}, \hat{\mathbf{B}_k}) = \frac{\sum{b_{i} * \hat{b_k}_{i}}} {\sqrt{(\sum{b_{i}^2})(\sum{\hat{b_k}_i^2})}}
\end{equation}

\subsection{\textbf {Best similarity of a given sequence number}}
This is for comparison(TODO: add an alg description, and a explaination why this kind of alg is cannot be applied)

Parameters to be used in this section are listed in table ~\ref {table:parameter}:
\begin{table}
\centering
\caption{parameters and their definition}
\begin{tabular}{|c|c|}
\hline
parameter & definition \\
\hline
N & resource candidates number, set to 20 in all experiments \\
\hline
$\epsilon$ & Algorithm ~\ref{alg:opt} \\
\hline
$\eta$ & Algorithm ~\ref{alg:final} \\
\hline
M & fragment size, set to 10, 20, 60, 100 in our experiments \\
\hline
\end{tabular}
\label{table:parameter}
\end{table}

\subsection{\textbf{compare to random alg}}
\label{sec:test01}
The compare result is show in figure ~\ref {fig:compare01}
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figure/compare01}
\caption{compare01}
\label{fig:compare01}
\end{figure}

The mean and mean squared error is shown in figure ~\ref{fig:meanAndStd01}
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figure/meanAndStd01}
\caption{compare01}
\label{fig:meanAndStd01}
\end{figure}

\subsection{\textbf{test 10 times}}
\label{sec:repeatTenTimes}
In our experiments, the capacity setting for each resource is determined by random,
and in section ~\ref{sec:test01} is only one test.

In this test, fragment number = 10 and repeat for 10 times.
Shown in figure ~\ref{fig:meanAndStdTemTimes}
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figure/meanAndStdTenTimes}
\caption{repeat 10 times}
\label{fig:meanAndStdTenTimes}
\end{figure}

\subsection{\textbf{test differnt $\eta$}}
In this test, for a given input distribution(so for transition matrix),
vary the factor affected by last selection(set to 0, 0.2, 0.4, 0.6, 0.8) to see the different,
repeat for 3 times.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figure/differentEta}
\caption{different eta}
\label{fig:differentEta}
\end{figure}

Based on this conclusion, we can repeat experiment ~\ref{sec:repeatTenTimes} under $\eta=1$,
shown as ~\ref{fig:meanAndStdTenTimes1}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figure/meanAndStdTenTimes1}
\caption{repeat 10 times under $\eta=1$}
\label{fig:meanAndStdTenTimes1}
\end{figure}



\subsection{\textbf{test different $\epsilon$ or step length}}
consider algorithm ~\ref{alg:num},  $\epsilon$ is the checkpoint to stop looping,
the smaller $\epsilon$, the more calculation, and the larger step-length.
step-length is defined as(TODO)...

This test will evalute the influence of $\epsilon$ or step-length,
refer to figure ~\ref{fig:differentEpsilon}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figure/differentEpsilon}
\caption{different eta}
\label{fig:differentEpsilon}
\end{figure}

\section{\textbf\normalsize{Apply Scenario}}

\section{\textbf\normalsize{Conclusion}}
To demonstrate the feasilibity of this algorithm, a simulation program is implemented 
as\\
\textbf{git@github.com:xiaodingbian/disk-allocation.git}.
In this repository, log file "result\_20\_40.log" is a running result with 20 VMs and 40 physical disks.
And cos similarity function is used to evaluate whether generated sequence for a few requests can 
follow to steady-state probability distribution.


\end{document}

